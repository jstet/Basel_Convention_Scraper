{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import unidecode\n",
    "import pycountry\n",
    "from geojson import FeatureCollection, dump\n",
    "import requests\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94025 entries, 0 to 94024\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   country                 94025 non-null  object\n",
      " 1   country_of_destination  93982 non-null  object\n",
      " 2   year                    94025 non-null  int64 \n",
      " 3   annex_3                 61801 non-null  object\n",
      " 4   annex_4_a               29088 non-null  object\n",
      " 5   annex_4_b               65992 non-null  object\n",
      " 6   amount                  93990 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144303/3925779474.py:1: DtypeWarning: Columns (0,1,2,3,5,12,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n",
    "df.info()\n",
    "initial_len = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "missing = df.isna().sum()\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "initial_annex_3 = int(missing_value_df.iloc[[3]].missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 country  \\\n0                                                Andorra   \n1                                                Andorra   \n2                                                Andorra   \n3                                                Andorra   \n4                                                Andorra   \n...                                                  ...   \n94020  United Kingdom of Great Britain and Northern I...   \n94021  United Kingdom of Great Britain and Northern I...   \n94022  United Kingdom of Great Britain and Northern I...   \n94023                                         Uzbekistan   \n94024                                         Uzbekistan   \n\n      country_of_destination  year       annex_3 annex_4_a annex_4_b  amount  \n0                         NZ  2021            H3       NaN    R1,R13   500.0  \n1                         PG  2021   H6.1,H8,H10     D5,D9       NaN   100.0  \n2                         PG  2021   H6.1,H8,H10     D5,D9       NaN   100.0  \n3                         NZ  2021  H6.1,H11,H12       NaN    R1,R13   300.0  \n4                         NZ  2021  H6.1,H11,H12       D10       NaN   250.0  \n...                      ...   ...           ...       ...       ...     ...  \n94020                     DE  2001          H4.2       NaN        R4  105.98  \n94021                     DE  2001          H4.2       NaN        R4  105.98  \n94022                     NO  2001       H10,H11       NaN     R3,R4     6.0  \n94023                     KZ  2001           NaN       NaN        R2  1683.7  \n94024                     TJ  2001           NaN       NaN        R5     4.6  \n\n[94025 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>country_of_destination</th>\n      <th>year</th>\n      <th>annex_3</th>\n      <th>annex_4_a</th>\n      <th>annex_4_b</th>\n      <th>amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H3</td>\n      <td>NaN</td>\n      <td>R1,R13</td>\n      <td>500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Andorra</td>\n      <td>PG</td>\n      <td>2021</td>\n      <td>H6.1,H8,H10</td>\n      <td>D5,D9</td>\n      <td>NaN</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Andorra</td>\n      <td>PG</td>\n      <td>2021</td>\n      <td>H6.1,H8,H10</td>\n      <td>D5,D9</td>\n      <td>NaN</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H6.1,H11,H12</td>\n      <td>NaN</td>\n      <td>R1,R13</td>\n      <td>300.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H6.1,H11,H12</td>\n      <td>D10</td>\n      <td>NaN</td>\n      <td>250.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94020</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>DE</td>\n      <td>2001</td>\n      <td>H4.2</td>\n      <td>NaN</td>\n      <td>R4</td>\n      <td>105.98</td>\n    </tr>\n    <tr>\n      <th>94021</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>DE</td>\n      <td>2001</td>\n      <td>H4.2</td>\n      <td>NaN</td>\n      <td>R4</td>\n      <td>105.98</td>\n    </tr>\n    <tr>\n      <th>94022</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>NO</td>\n      <td>2001</td>\n      <td>H10,H11</td>\n      <td>NaN</td>\n      <td>R3,R4</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>94023</th>\n      <td>Uzbekistan</td>\n      <td>KZ</td>\n      <td>2001</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>R2</td>\n      <td>1683.7</td>\n    </tr>\n    <tr>\n      <th>94024</th>\n      <td>Uzbekistan</td>\n      <td>TJ</td>\n      <td>2001</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>R5</td>\n      <td>4.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>94025 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing country names\n",
    "### Converting country name to its alpha 2 code (https://en.wikipedia.org/wiki/ISO_3166-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    # -- Cleaning and formatting country name strings to get recognized by pycountry --\n",
    "    # removing whitespace from beginning and end so country names get recognized properly\n",
    "    temp = x.strip()\n",
    "    # e.g. \"Venezuela (Bolivarian Republic of) -> \"Venezuela, Bolivarian Republic of\"\n",
    "    temp = temp.replace(\" (\",\", \").replace(\")\",\"\")\n",
    "    # Côte d´Ivoire --> Côte d'Ivoire\n",
    "    temp = temp.replace(\"´\", \"'\")\n",
    "    # Handling\n",
    "    if temp == \"United Kingdom of Great Britain and Northern Ireland\":\n",
    "        temp = \"United Kingdom\"\n",
    "    if temp == \"Türkiye\":\n",
    "        temp = \"Turkey\"\n",
    "    if temp == \"Swaziland\":\n",
    "        temp = \"Eswatini\"\n",
    "    if temp == \"Republic of Moldova\":\n",
    "        temp = \"Moldova, Republic of\"\n",
    "    if temp == \"Democratic Republic of the Congo\" or temp == \"Congo, Democratic Republic of the\" or temp == \"Congo, Republic of the\":\n",
    "        temp = \"Congo, The Democratic Republic of the\"\n",
    "    if temp == \"State of Palestine\":\n",
    "        temp = \"Palestine, State of\"\n",
    "    if temp == \"Bolivia\":\n",
    "        temp = \"Bolivia, Plurinational State of\"\n",
    "     # -- Converting country name to alpha_2 code, which is what the other columns use --\n",
    "    return pycountry.countries.get(name=temp).alpha_2.lower()\n",
    "\n",
    "df[\"country\"] = df[\"country\"].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if alpha 2 codes of other columns are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "CS\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "SP\n",
      "SP\n",
      "F\n",
      "F\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "TR,D\n",
      "BY,D\n",
      "Eire\n",
      "YU\n"
     ]
    }
   ],
   "source": [
    "def check(x):\n",
    "    if not pd.isna(x):\n",
    "        temp = x.strip()\n",
    "        temp = unidecode.unidecode(temp)\n",
    "        temp = temp.replace(\"\\xa0\", \"\")\n",
    "        if temp == \"\":\n",
    "            return np.nan\n",
    "        temp = \"\".join([ c if c.isalnum() else \"\" for c in temp ])\n",
    "        if temp == \"UK\":\n",
    "            temp = \"GB\"\n",
    "        country = pycountry.countries.get(alpha_2=temp)\n",
    "        if country is None:\n",
    "            country = pycountry.countries.get(alpha_3=temp)\n",
    "            if country is None:\n",
    "                # There are still some invalid values left. We treat them as typos and therefore as nan, because we cannot infer the code that the official wanted to enter\n",
    "                print(x)\n",
    "                return np.nan\n",
    "            else:\n",
    "                return country.alpha_2.lower()\n",
    "        else:\n",
    "            return temp.lower()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"country_of_destination\"] = df[\"country_of_destination\"].apply(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning code columns (annex_3, annex_4_a, annex_4_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# NEEDS CONFIRMATION\n",
    "# Valid codes\n",
    "unique_items_a_3 = (\"H1\",\"H3\",\"H4.1\",\"H4.2\",\"H4.3\",\"H5.1\",\"H5.2\",\"H6.1\",\"H6.2\",\"H8\",\"H10\",\"H11\",\"H12\",\"H13\")\n",
    "unique_items_un = [\"UN1\",\"UN3\",\"UN4.1\",\"UN4.2\",\"UN4.3\",\"UN5.1\",\"UN5.2\",\"UN6.1\",\"UN6.2\",\"UN8\",\"UN9\"]\n",
    "unique_items_a_4_a = [f\"D{x}\" for x in range(1,17)]\n",
    "unique_items_a_4_b = [f\"R{x}\" for x in range(1,14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def init_clean(x):\n",
    "    temp = x.upper()\n",
    "    temp = temp.strip()\n",
    "    # deleting .0 because not part of official codes\n",
    "    temp = temp.replace(\".0\", \"\")\n",
    "    #sometimes someone writes e.g. H03, but 0 never part of official codes\n",
    "    temp = temp.replace(\"0\",\"\")\n",
    "    #sometimes people use whitespace to separate the letter and the number\n",
    "    #temp = temp.replace(\" \",\"\")\n",
    "    \n",
    "    # additional\n",
    "    temp = temp.replace(\"E\",\"\")\n",
    "    temp = temp.replace(\"N\",\"\")\n",
    "    temp = temp.replace(\"'\",\"\")\n",
    "    temp2 = list(temp)\n",
    "    for i, v in enumerate(temp2):\n",
    "        if i>0 and v==' ' and temp2[i-1] == 'H':\n",
    "            del temp2[i] \n",
    "            del i\n",
    "    temp = \"\".join(temp2) \n",
    "    \n",
    "    d = 'H' \n",
    "    temp = [d + e for e in temp.split(d)]\n",
    "    temp = [e[:-1] if e[-1] == \".\" else e for e in temp]\n",
    "    temp = [e[:-1] if e[-1] == \"H\" else e for e in temp]\n",
    "    temp = [e.replace(' ', '') for e in temp]\n",
    "    temp = [e.replace('Y', '') for e in temp]\n",
    "    temp = [e.replace('B', '') for e in temp]\n",
    "    temp = [e.replace('(', '') for e in temp]\n",
    "    temp = [e.replace('P', '') for e in temp]\n",
    "    temp = [e.replace(')', '') for e in temp]\n",
    "    temp = [e.replace('A', '') for e in temp]\n",
    "    temp = list(filter(None, temp))\n",
    "    return temp\n",
    "\n",
    "def cleaning_codes(x, letter, unique):\n",
    "    if not pd.isna(x):\n",
    "        if x == \"\" or x == \"--\" or x == \"-\":\n",
    "            return np.nan\n",
    "        temp = unidecode.unidecode(x)\n",
    "        # converting cell to list, because sometimes it contains more than one value, replacing other possible separators with commas\n",
    "        temp = temp.replace(\"/\", \",\").replace(\";\",\",\").replace(\"\\n\",\",\").replace(\"，\", \",\")\n",
    "        # basic cleaning\n",
    "        lst = [init_clean(x) for x in temp.split(\",\")]\n",
    "        \n",
    "        # NEW: flatten list if nested \n",
    "        lst = flatten(lst)\n",
    "        \n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes cell contains only a number. we are assuming they just didn't add the letter (H for example) in this case\n",
    "        lst = [letter + x if letter not in x else x for x in lst]\n",
    "\n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes a cell contains something like this: \"R_\". We are treating this as nan\n",
    "        lst = [x for x in lst if not f\"{letter}_\" in x and not f\"{letter}*\" in x]\n",
    "        if lst != []:\n",
    "           # print(lst)\n",
    "         #   lst = [d + e for e in lst[0].split(d) if e and len(lst)==1]\n",
    "         #   lst = [e[:-1] if e[-1] == \".\" else e for e in lst]\n",
    "            return lst\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: cleaning_codes(x[\"annex_3\"], \"H\", unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_a\"], \"D\", unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_b\"], \"R\", unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some invalid values left. Some are just typos.We convert them to nan because we cannot infer the code that the official wanted to enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": "['H6.1.',\n 'H4',\n 'H8.',\n 'H17',\n 'HXX',\n 'HR',\n 'H12.1',\n 'H14',\n 'H14U',\n 'HOC',\n 'H3.1',\n 'HJ',\n 'H5',\n 'H1.1',\n 'HOTSCIFID',\n 'H9',\n 'H7',\n 'H11.12',\n 'H1.8',\n 'H4.4',\n 'H6',\n 'H6.13',\n 'H4999999999999996',\n 'H8.1',\n 'H18',\n 'H34',\n 'HTC',\n 'HZ',\n 'H61',\n 'H41',\n 'H112',\n 'H15',\n 'H5.5',\n 'H31',\n 'H4.1.',\n 'H2',\n 'H811',\n 'H.',\n 'HOTLISTD',\n 'H3.4',\n 'H6.1-8',\n 'H1-',\n 'H33-35',\n 'H',\n 'HJFRL']"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I think we can improve cleaning\n",
    "v = list(set(list(df[df[\"annex_3\"].notna()][\"annex_3\"].explode().unique())) - set(unique_items_a_3))\n",
    "print(len(v))\n",
    "v # 107 -> 97 -> 88 -> 62 -> 56 -> 54 -> 52 -> 49 -> 45 -> 42 -> 45 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['HD1',\n 'HD',\n 'HD19',\n 'HD15',\n 'DHR',\n 'DHJ',\n 'DHZ',\n 'HD18',\n 'HD4',\n 'DHLV',\n 'HD8',\n 'DHU',\n 'HD12',\n 'DHC',\n 'DH',\n 'DHR5',\n 'HD16',\n 'DHT',\n 'HD2',\n 'HD9',\n 'HD17',\n 'DHR3',\n 'HD14',\n 'DHKR',\n 'HD6',\n 'DH13',\n 'HD13',\n 'HD3',\n 'HD13+D1',\n 'HDXX',\n 'DHG',\n 'DHR4',\n 'HD5',\n 'HD11',\n 'DHIL',\n 'DH1']"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(list(df[df[\"annex_4_a\"].notna()][\"annex_4_a\"].explode().unique())) - set(unique_items_a_4_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['HR14',\n 'HRXX',\n 'HR12',\n 'HR',\n 'RHD1',\n 'HR11',\n 'RH9',\n 'HR9',\n 'RH5',\n 'HR16',\n 'HMIXDR',\n 'HR8',\n 'HR6',\n 'HR5',\n 'HR7',\n 'HR1',\n 'RHD12',\n 'HR4',\n 'HR15',\n 'HR3',\n 'HR13',\n 'HR2']"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(list(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"].explode().unique())) - set(unique_items_a_4_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(lst,valid):\n",
    "    if isinstance(lst, list):\n",
    "        temp = [x for x in lst if x in valid]\n",
    "        if temp != []:\n",
    "            return temp\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: func(x[\"annex_3\"], unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: func(x[\"annex_4_a\"], unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: func(x[\"annex_4_b\"], unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "38718"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['annex_3'].isnull().sum() # urspr. 38 909 -> 38 728 -> 38 720 -> 38 718\n",
    "#len(df) #-> 93004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_code(h_code):\n",
    "    if isinstance(h_code, list):\n",
    "        return [s.replace(\"H\", \"UN\") if s not in (\"H10\", \"H11\", \"H12\", \"H13\") else \"UN9\" for s in h_code]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UN_code'] = df['annex_3'].apply(un_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        if isinstance(x, float):\n",
    "            return x\n",
    "        else:\n",
    "            temp = str(x)\n",
    "            # removing whitespace\n",
    "            temp = temp.replace(\" \", \"\")\n",
    "            # converting , to .\n",
    "            temp = temp.replace(\",\",\".\")\n",
    "            # replacing all non numeric characters but .\n",
    "            temp = re.sub(\"[^0-9.]\", \"\", temp)\n",
    "            temp = float(temp)\n",
    "            return temp\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"amount\"] = df.apply(lambda x: func(x[\"amount\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"year\"] = df.apply(lambda x: func(x[\"year\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop all rows that have missing values for amount and country_of_destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"country\"]==\"NA\"] = np.nan\n",
    "df = df[df['amount'].notna()]\n",
    "df = df[df['country_of_destination'].notna()]\n",
    "df = df[df['country'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost 84 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lost {initial_len - len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " after processing 6443 less rows of annex_3. Initial value: 32224\n"
     ]
    },
    {
     "data": {
      "text/plain": "      country country_of_destination    year           annex_3  annex_4_a  \\\n0          ad                     nz  2021.0              [H3]        NaN   \n1          ad                     pg  2021.0    [H6.1, H8, H1]        NaN   \n2          ad                     pg  2021.0    [H6.1, H8, H1]        NaN   \n3          ad                     nz  2021.0  [H6.1, H11, H12]        NaN   \n4          ad                     nz  2021.0  [H6.1, H11, H12]        NaN   \n...       ...                    ...     ...               ...        ...   \n94020      gb                     de  2001.0            [H4.2]        NaN   \n94021      gb                     de  2001.0            [H4.2]        NaN   \n94022      gb                     no  2001.0         [H1, H11]        NaN   \n94023      uz                     kz  2001.0               NaN        NaN   \n94024      uz                     tj  2001.0               NaN        NaN   \n\n       annex_4_b   amount            UN_code  \n0            NaN   500.00              [UN3]  \n1            NaN   100.00  [UN6.1, UN8, UN1]  \n2            NaN   100.00  [UN6.1, UN8, UN1]  \n3            NaN   300.00  [UN6.1, UN9, UN9]  \n4            NaN   250.00  [UN6.1, UN9, UN9]  \n...          ...      ...                ...  \n94020        NaN   105.98            [UN4.2]  \n94021        NaN   105.98            [UN4.2]  \n94022        NaN     6.00         [UN1, UN9]  \n94023        NaN  1683.70                NaN  \n94024        NaN     4.60                NaN  \n\n[93941 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>country_of_destination</th>\n      <th>year</th>\n      <th>annex_3</th>\n      <th>annex_4_a</th>\n      <th>annex_4_b</th>\n      <th>amount</th>\n      <th>UN_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H3]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>500.00</td>\n      <td>[UN3]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN6.1, UN8, UN1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN6.1, UN8, UN1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>300.00</td>\n      <td>[UN6.1, UN9, UN9]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>250.00</td>\n      <td>[UN6.1, UN9, UN9]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94020</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n    </tr>\n    <tr>\n      <th>94021</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n    </tr>\n    <tr>\n      <th>94022</th>\n      <td>gb</td>\n      <td>no</td>\n      <td>2001.0</td>\n      <td>[H1, H11]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.00</td>\n      <td>[UN1, UN9]</td>\n    </tr>\n    <tr>\n      <th>94023</th>\n      <td>uz</td>\n      <td>kz</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1683.70</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>94024</th>\n      <td>uz</td>\n      <td>tj</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.60</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>93941 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isna().sum()\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "print(f\" after processing {int(missing_value_df.iloc[[3]].missing) - initial_annex_3} less rows of annex_3. Initial value: {initial_annex_3}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with same origin & destination country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.where(df.country_of_destination==df.country)\n",
    "C = list(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deletion of flows with same origin & destination in total 937 less rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"After deletion of flows with same origin & destination in total {len(C)} less rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UN code 9 often more than one time in UN_code list\n",
    "def unique(h_code):\n",
    "    if type(h_code)!= float:\n",
    "        return np.unique(h_code)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      country country_of_destination    year           annex_3  annex_4_a  \\\n0          ad                     nz  2021.0              [H3]        NaN   \n1          ad                     pg  2021.0    [H6.1, H8, H1]        NaN   \n2          ad                     pg  2021.0    [H6.1, H8, H1]        NaN   \n3          ad                     nz  2021.0  [H6.1, H11, H12]        NaN   \n4          ad                     nz  2021.0  [H6.1, H11, H12]        NaN   \n...       ...                    ...     ...               ...        ...   \n94020      gb                     de  2001.0            [H4.2]        NaN   \n94021      gb                     de  2001.0            [H4.2]        NaN   \n94022      gb                     no  2001.0         [H1, H11]        NaN   \n94023      uz                     kz  2001.0               NaN        NaN   \n94024      uz                     tj  2001.0               NaN        NaN   \n\n       annex_4_b   amount            UN_code  \n0            NaN   500.00              [UN3]  \n1            NaN   100.00  [UN1, UN6.1, UN8]  \n2            NaN   100.00  [UN1, UN6.1, UN8]  \n3            NaN   300.00       [UN6.1, UN9]  \n4            NaN   250.00       [UN6.1, UN9]  \n...          ...      ...                ...  \n94020        NaN   105.98            [UN4.2]  \n94021        NaN   105.98            [UN4.2]  \n94022        NaN     6.00         [UN1, UN9]  \n94023        NaN  1683.70                NaN  \n94024        NaN     4.60                NaN  \n\n[93004 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>country_of_destination</th>\n      <th>year</th>\n      <th>annex_3</th>\n      <th>annex_4_a</th>\n      <th>annex_4_b</th>\n      <th>amount</th>\n      <th>UN_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H3]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>500.00</td>\n      <td>[UN3]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN1, UN6.1, UN8]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN1, UN6.1, UN8]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>300.00</td>\n      <td>[UN6.1, UN9]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>250.00</td>\n      <td>[UN6.1, UN9]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94020</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n    </tr>\n    <tr>\n      <th>94021</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n    </tr>\n    <tr>\n      <th>94022</th>\n      <td>gb</td>\n      <td>no</td>\n      <td>2001.0</td>\n      <td>[H1, H11]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.00</td>\n      <td>[UN1, UN9]</td>\n    </tr>\n    <tr>\n      <th>94023</th>\n      <td>uz</td>\n      <td>kz</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1683.70</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>94024</th>\n      <td>uz</td>\n      <td>tj</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.60</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>93004 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['UN_code'] = df['UN_code'].apply(unique)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newdf = df[df[\"UN_code\"].apply(lambda x: type(x) != float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2850788773185773 percent of the total amount belongs to multiple categories.\n"
     ]
    }
   ],
   "source": [
    "newerdf = newdf[newdf[\"UN_code\"].apply(lambda x: len(x) > 1)]\n",
    "newerdf\n",
    "print(f'{newerdf[\"amount\"].sum() / df[\"amount\"].sum() *100} percent of the total amount belongs to multiple categories.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8081"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)-len(newdf)\n",
    "len(newerdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.8062173294868 percent of the total amount belongs NaN h code.\n"
     ]
    }
   ],
   "source": [
    "noCode = df[df[\"UN_code\"].apply(lambda x: type(x) == float)]\n",
    "total_amount = df[\"amount\"].sum()\n",
    "print(f'{noCode[\"amount\"].sum() / df[\"amount\"].sum() *100} percent of the total amount belongs NaN h code.') #65.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating separate columns for codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[unique_items_un + [\"multiple\", \"unspecified\"]] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if type(row[\"UN_code\"]) != float:\n",
    "        if len(row[\"UN_code\"]) == 1:\n",
    "            df.loc[index, row[\"UN_code\"][0]] = row[\"amount\"]\n",
    "        else:\n",
    "            df.loc[index, \"multiple\"] = row[\"amount\"]\n",
    "    else:\n",
    "        df.loc[index, \"unspecified\"] = row[\"amount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming and deleting colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "total_amount = df[\"amount\"].sum()\n",
    "df.rename(columns={\"country\": \"origin\", \"country_of_destination\": \"destination\"}, inplace=True)\n",
    "df.drop(['amount', 'UN_code', \"annex_3\", \"annex_4_a\", \"annex_4_b\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"origin\",\"destination\",\"year\"]\n",
    "agg_functions = {\"UN1\" : \"sum\" ,\"UN3\": \"sum\",\"UN4.1\": \"sum\",\"UN4.2\": \"sum\",\"UN4.3\": \"sum\",\"UN5.1\": \"sum\",\"UN5.2\": \"sum\",\"UN6.1\": \"sum\",\"UN6.2\": \"sum\",\"UN8\": \"sum\",\"UN9\": \"sum\", \"unspecified\": \"sum\", \"multiple\": \"sum\"}\n",
    "df_new = df.groupby(cols, dropna=False).aggregate(agg_functions).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     origin destination    year  UN1  UN3  UN4.1  UN4.2  UN4.3  UN5.1  UN5.2  \\\n0        ad          es  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n1        ad          es  2003.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n2        ad          es  2004.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n3        ad          es  2005.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n4        ad          es  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n...     ...         ...     ...  ...  ...    ...    ...    ...    ...    ...   \n8114     za          se  2015.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8115     za          sg  2010.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8116     za          tr  2018.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8117     zm          fi  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8118     zm          za  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n\n      UN6.1  UN6.2  UN8     UN9  unspecified  multiple  \n0       0.0    0.0  0.0     0.0     7777.400      0.00  \n1       0.0    0.0  0.0     0.0      486.800      0.00  \n2       0.0    0.0  0.0     0.0      425.980      0.00  \n3       0.0    0.0  0.0     0.0      621.950      0.00  \n4       0.0    0.0  0.0     0.0     1044.092      0.00  \n...     ...    ...  ...     ...          ...       ...  \n8114    0.0    0.0  0.0  1000.0        0.000      0.00  \n8115    0.0    0.0  0.0   720.0        0.000      0.00  \n8116    0.0    0.0  0.0     0.0        0.000     21.24  \n8117    0.0    0.0  0.0     0.0      235.000      0.00  \n8118    0.0    0.0  0.0     0.0        1.700      0.00  \n\n[8119 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7777.400</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2003.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>486.800</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2004.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>425.980</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2005.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>621.950</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1044.092</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8114</th>\n      <td>za</td>\n      <td>se</td>\n      <td>2015.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8115</th>\n      <td>za</td>\n      <td>sg</td>\n      <td>2010.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>720.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8116</th>\n      <td>za</td>\n      <td>tr</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>21.24</td>\n    </tr>\n    <tr>\n      <th>8117</th>\n      <td>zm</td>\n      <td>fi</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8118</th>\n      <td>zm</td>\n      <td>za</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.700</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8119 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2850788773185777 percent of total amount is multiple\n",
      "0.15751210434176735 percent of the total amount belongs UN1.\n",
      "1.9519335402276246 percent of the total amount belongs UN3.\n",
      "1.7667412981062773 percent of the total amount belongs UN4.1.\n",
      "0.1044700110039856 percent of the total amount belongs UN4.2.\n",
      "0.7825004992082472 percent of the total amount belongs UN4.3.\n",
      "0.0904507944169156 percent of the total amount belongs UN5.1.\n",
      "0.005156365279592412 percent of the total amount belongs UN5.2.\n",
      "2.6801735314085673 percent of the total amount belongs UN6.1.\n",
      "0.40651103679667727 percent of the total amount belongs UN6.2.\n",
      "3.464927972355394 percent of the total amount belongs UN8.\n",
      "20.498326640049562 percent of the total amount belongs UN9.\n",
      "65.8062173294868 percent of the total amount is unspecified.\n"
     ]
    }
   ],
   "source": [
    "overall = [\"UN1\", \"UN3\", \"UN4.1\", \"UN4.2\", \"UN4.3\", \"UN5.1\", \"UN5.2\", \"UN6.1\", \"UN6.2\", \"UN8\", \"UN9\"]\n",
    "print(f'{df_new[\"multiple\"].sum() / total_amount *100} percent of total amount is multiple')\n",
    "print(f'{(df_new[\"UN1\"].sum()) / total_amount *100} percent of the total amount belongs UN1.')\n",
    "print(f'{(df_new[\"UN3\"].sum()) / total_amount *100} percent of the total amount belongs UN3.')\n",
    "print(f'{(df_new[\"UN4.1\"].sum()) / total_amount *100} percent of the total amount belongs UN4.1.')\n",
    "print(f'{(df_new[\"UN4.2\"].sum()) / total_amount *100} percent of the total amount belongs UN4.2.')\n",
    "print(f'{(df_new[\"UN4.3\"].sum()) / total_amount *100} percent of the total amount belongs UN4.3.')\n",
    "print(f'{(df_new[\"UN5.1\"].sum()) / total_amount *100} percent of the total amount belongs UN5.1.')\n",
    "print(f'{(df_new[\"UN5.2\"].sum()) / total_amount *100} percent of the total amount belongs UN5.2.')\n",
    "print(f'{(df_new[\"UN6.1\"].sum()) / total_amount *100} percent of the total amount belongs UN6.1.')\n",
    "print(f'{(df_new[\"UN6.2\"].sum()) / total_amount *100} percent of the total amount belongs UN6.2.')\n",
    "print(f'{(df_new[\"UN8\"].sum()) / total_amount *100} percent of the total amount belongs UN8.')\n",
    "print(f'{(df_new[\"UN9\"].sum()) / total_amount *100} percent of the total amount belongs UN9.')\n",
    "print(f'{df_new[\"unspecified\"].sum() / total_amount *100} percent of the total amount is unspecified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198 of 8119 rows have an amount of zero everywhere but unspecified or multiple\n",
      "525 of 8119 rows have an amount of zero everywhere but unspecified\n",
      "2776 of 8119 rows have no amount on unspecified and multiple\n",
      "4237 of 8119 rows have an amount on unspecified\n",
      "1649 of 8119 rows have an amount on multiple\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df_new[(df_new.iloc[:,3:14] == 0).all(axis=1)])} of {len(df_new)} rows have an amount of zero everywhere but unspecified or multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,3:15] == 0).all(axis=1)])} of {len(df_new)} rows have an amount of zero everywhere but unspecified\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:] == 0).all(axis=1)])} of {len(df_new)} rows have no amount on unspecified and multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:15] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on unspecified\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,15:16] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on multiple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     origin destination  year  UN1  UN3  UN4.1  UN4.2  UN4.3  UN5.1  UN5.2  \\\n0        ad          es  2002  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n1        ad          es  2003  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n2        ad          es  2004  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n3        ad          es  2005  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n4        ad          es  2006  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n...     ...         ...   ...  ...  ...    ...    ...    ...    ...    ...   \n8114     za          se  2015  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8115     za          sg  2010  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8116     za          tr  2018  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8117     zm          fi  2002  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8118     zm          za  2006  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n\n      UN6.1  UN6.2  UN8     UN9  unspecified  multiple  \n0       0.0    0.0  0.0     0.0     7777.400      0.00  \n1       0.0    0.0  0.0     0.0      486.800      0.00  \n2       0.0    0.0  0.0     0.0      425.980      0.00  \n3       0.0    0.0  0.0     0.0      621.950      0.00  \n4       0.0    0.0  0.0     0.0     1044.092      0.00  \n...     ...    ...  ...     ...          ...       ...  \n8114    0.0    0.0  0.0  1000.0        0.000      0.00  \n8115    0.0    0.0  0.0   720.0        0.000      0.00  \n8116    0.0    0.0  0.0     0.0        0.000     21.24  \n8117    0.0    0.0  0.0     0.0      235.000      0.00  \n8118    0.0    0.0  0.0     0.0        1.700      0.00  \n\n[8119 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7777.400</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2003</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>486.800</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2004</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>425.980</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>621.950</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1044.092</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8114</th>\n      <td>za</td>\n      <td>se</td>\n      <td>2015</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8115</th>\n      <td>za</td>\n      <td>sg</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>720.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8116</th>\n      <td>za</td>\n      <td>tr</td>\n      <td>2018</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>21.24</td>\n    </tr>\n    <tr>\n      <th>8117</th>\n      <td>zm</td>\n      <td>fi</td>\n      <td>2002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8118</th>\n      <td>zm</td>\n      <td>za</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.700</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8119 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_new[\"year\"] = df_new.apply(lambda x: func(x[\"year\"]), axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [origin, destination, year, UN1, UN3, UN4.1, UN4.2, UN4.3, UN5.1, UN5.2, UN6.1, UN6.2, UN8, UN9, unspecified, multiple]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new[\"origin\"]==\"tj\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_new.to_csv(\"../output/processed/flows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Source: https://towardsdatascience.com/dealing-with-list-values-in-pandas-dataframes-a177e534f173\n",
    "# def boolean_df(item_lists, unique_items):# Create empty dict\n",
    "#     bool_dict = {}\n",
    "#\n",
    "#     # Loop through all the tags\n",
    "#     for i, item in enumerate(unique_items):\n",
    "#         # Apply boolean mask\n",
    "#         bool_dict[item] = item_lists.apply(lambda x: item in x)\n",
    "#\n",
    "#     # Return the results as a dataframe\n",
    "#     return pd.DataFrame(bool_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"annex_3\"].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df_bool_h = boolean_df(df[df[\"annex_3\"].notna()][\"annex_3\"], unique_items_a_3)\n",
    "# df_bool_d = boolean_df(df[df['annex_4_a'].notna()][\"annex_4_a\"], unique_items_a_4_a)\n",
    "# df_bool_r = boolean_df(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"], unique_items_a_4_b)\n",
    "# df_bool_un = boolean_df(df[df[\"UN_code\"].notna()][\"UN_code\"], unique_items_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # only using un code for now\n",
    "# df = pd.concat([df[[\"country\", \"country_of_destination\", \"year\", \"amount\"]], df_bool_un], axis=1)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# # df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])] = df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "# TOKEN=os.getenv(\"MAPBOX_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# headers = {'Accept': 'application/json'}\n",
    "# dct = {}\n",
    "# countries = list(df.country.unique())\n",
    "# for i in countries:\n",
    "#     url = f\"https://api.mapbox.com/geocoding/v5/mapbox.places/{i}.json?&types=country&access_token={TOKEN}\"\n",
    "#     r = requests.get(url)\n",
    "#     jason = r.json()\n",
    "#     dct[i] = jason[\"features\"][0][\"center\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     lat = dct[x][0]\n",
    "#     lon = dct[x][1]\n",
    "#     return lat,lon\n",
    "#\n",
    "#\n",
    "# df[\"origin_lat\"],df[\"origin_lon\"] = df.apply(lambda x: func(x[\"country\"]), axis=1)\n",
    "# df[\"destination_lat\"],df[\"destination_lon\"] = df.apply(lambda x: func(x[\"country_of_destination\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# for i in countries:\n",
    "#     df.loc[df[\"country\"] == i, \"lat_origin\"]=dct[i][1]\n",
    "#     df.loc[df[\"country\"] == i, \"lon_origin\"]=dct[i][0]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lat_destination\"]=dct[i][1]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lon_destination\"]=dct[i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"../output/processed/clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
