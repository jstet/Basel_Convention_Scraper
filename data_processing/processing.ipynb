{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import unidecode\n",
    "import pycountry\n",
    "from geojson import FeatureCollection, dump\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94025 entries, 0 to 94024\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   country                 94025 non-null  object\n",
      " 1   country_of_destination  93982 non-null  object\n",
      " 2   year                    94025 non-null  int64 \n",
      " 3   annex_3                 61801 non-null  object\n",
      " 4   annex_4_a               29088 non-null  object\n",
      " 5   annex_4_b               65992 non-null  object\n",
      " 6   amount                  93990 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25147/3925779474.py:1: DtypeWarning: Columns (0,1,2,3,5,12,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n",
    "df.info()\n",
    "initial_len = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "missing = df.isna().sum()\n",
    "initial len\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "initial_annex_3 = int(missing_value_df.iloc[[3]].missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 country  \\\n0                                                Andorra   \n1                                                Andorra   \n2                                                Andorra   \n3                                                Andorra   \n4                                                Andorra   \n...                                                  ...   \n94020  United Kingdom of Great Britain and Northern I...   \n94021  United Kingdom of Great Britain and Northern I...   \n94022  United Kingdom of Great Britain and Northern I...   \n94023                                         Uzbekistan   \n94024                                         Uzbekistan   \n\n      country_of_destination  year       annex_3 annex_4_a annex_4_b  amount  \n0                         NZ  2021            H3       NaN    R1,R13   500.0  \n1                         PG  2021   H6.1,H8,H10     D5,D9       NaN   100.0  \n2                         PG  2021   H6.1,H8,H10     D5,D9       NaN   100.0  \n3                         NZ  2021  H6.1,H11,H12       NaN    R1,R13   300.0  \n4                         NZ  2021  H6.1,H11,H12       D10       NaN   250.0  \n...                      ...   ...           ...       ...       ...     ...  \n94020                     DE  2001          H4.2       NaN        R4  105.98  \n94021                     DE  2001          H4.2       NaN        R4  105.98  \n94022                     NO  2001       H10,H11       NaN     R3,R4     6.0  \n94023                     KZ  2001           NaN       NaN        R2  1683.7  \n94024                     TJ  2001           NaN       NaN        R5     4.6  \n\n[94025 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>country_of_destination</th>\n      <th>year</th>\n      <th>annex_3</th>\n      <th>annex_4_a</th>\n      <th>annex_4_b</th>\n      <th>amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H3</td>\n      <td>NaN</td>\n      <td>R1,R13</td>\n      <td>500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Andorra</td>\n      <td>PG</td>\n      <td>2021</td>\n      <td>H6.1,H8,H10</td>\n      <td>D5,D9</td>\n      <td>NaN</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Andorra</td>\n      <td>PG</td>\n      <td>2021</td>\n      <td>H6.1,H8,H10</td>\n      <td>D5,D9</td>\n      <td>NaN</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H6.1,H11,H12</td>\n      <td>NaN</td>\n      <td>R1,R13</td>\n      <td>300.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Andorra</td>\n      <td>NZ</td>\n      <td>2021</td>\n      <td>H6.1,H11,H12</td>\n      <td>D10</td>\n      <td>NaN</td>\n      <td>250.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94020</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>DE</td>\n      <td>2001</td>\n      <td>H4.2</td>\n      <td>NaN</td>\n      <td>R4</td>\n      <td>105.98</td>\n    </tr>\n    <tr>\n      <th>94021</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>DE</td>\n      <td>2001</td>\n      <td>H4.2</td>\n      <td>NaN</td>\n      <td>R4</td>\n      <td>105.98</td>\n    </tr>\n    <tr>\n      <th>94022</th>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>NO</td>\n      <td>2001</td>\n      <td>H10,H11</td>\n      <td>NaN</td>\n      <td>R3,R4</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>94023</th>\n      <td>Uzbekistan</td>\n      <td>KZ</td>\n      <td>2001</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>R2</td>\n      <td>1683.7</td>\n    </tr>\n    <tr>\n      <th>94024</th>\n      <td>Uzbekistan</td>\n      <td>TJ</td>\n      <td>2001</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>R5</td>\n      <td>4.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>94025 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing country names\n",
    "### Converting country name to its alpha 2 code (https://en.wikipedia.org/wiki/ISO_3166-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    # -- Cleaning and formatting country name strings to get recognized by pycountry --\n",
    "    # removing whitespace from beginning and end so country names get recognized properly\n",
    "    temp = x.strip()\n",
    "    # e.g. \"Venezuela (Bolivarian Republic of) -> \"Venezuela, Bolivarian Republic of\"\n",
    "    temp = temp.replace(\" (\",\", \").replace(\")\",\"\")\n",
    "    # Côte d´Ivoire --> Côte d'Ivoire\n",
    "    temp = temp.replace(\"´\", \"'\")\n",
    "    # Handling\n",
    "    if temp == \"United Kingdom of Great Britain and Northern Ireland\":\n",
    "        temp = \"United Kingdom\"\n",
    "    if temp == \"Türkiye\":\n",
    "        temp = \"Turkey\"\n",
    "    if temp == \"Swaziland\":\n",
    "        temp = \"Eswatini\"\n",
    "    if temp == \"Republic of Moldova\":\n",
    "        temp = \"Moldova, Republic of\"\n",
    "    if temp == \"Democratic Republic of the Congo\" or temp == \"Congo, Democratic Republic of the\" or temp == \"Congo, Republic of the\":\n",
    "        temp = \"Congo, The Democratic Republic of the\"\n",
    "    if temp == \"State of Palestine\":\n",
    "        temp = \"Palestine, State of\"\n",
    "    if temp == \"Bolivia\":\n",
    "        temp = \"Bolivia, Plurinational State of\"\n",
    "     # -- Converting country name to alpha_2 code, which is what the other columns use --\n",
    "    return pycountry.countries.get(name=temp).alpha_2.lower()\n",
    "\n",
    "df[\"country\"] = df[\"country\"].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if alpha 2 codes of other columns are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "CS\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "HL\n",
      "SP\n",
      "SP\n",
      "F\n",
      "F\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "GB,B\n",
      "TR,D\n",
      "BY,D\n",
      "Eire\n",
      "YU\n"
     ]
    }
   ],
   "source": [
    "def check(x):\n",
    "    if not pd.isna(x):\n",
    "        temp = x.strip()\n",
    "        temp = unidecode.unidecode(temp)\n",
    "        temp = temp.replace(\"\\xa0\", \"\")\n",
    "        if temp == \"\":\n",
    "            return np.nan\n",
    "        temp = \"\".join([ c if c.isalnum() else \"\" for c in temp ])\n",
    "        if temp == \"UK\":\n",
    "            temp = \"GB\"\n",
    "        country = pycountry.countries.get(alpha_2=temp)\n",
    "        if country is None:\n",
    "            country = pycountry.countries.get(alpha_3=temp)\n",
    "            if country is None:\n",
    "                # There are still some invalid values left. We treat them as typos and therefore as nan, because we cannot infer the code that the official wanted to enter\n",
    "                print(x)\n",
    "                return np.nan\n",
    "            else:\n",
    "                return country.alpha_2.lower()\n",
    "        else:\n",
    "            return temp.lower()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"country_of_destination\"] = df[\"country_of_destination\"].apply(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning code columns (annex_3, annex_4_a, annex_4_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# NEEDS CONFIRMATION\n",
    "# Valid codes\n",
    "unique_items_a_3 = (\"H1\",\"H3\",\"H4.1\",\"H4.2\",\"H4.3\",\"H5.1\",\"H5.2\",\"H6.1\",\"H6.2\",\"H8\",\"H10\",\"H11\",\"H12\",\"H13\")\n",
    "unique_items_un = [\"UN1\",\"UN3\",\"UN4.1\",\"UN4.2\",\"UN4.3\",\"UN5.1\",\"UN5.2\",\"UN6.1\",\"UN6.2\",\"UN8\",\"UN9\"]\n",
    "unique_items_a_4_a = [f\"D{x}\" for x in range(1,17)]\n",
    "unique_items_a_4_b = [f\"R{x}\" for x in range(1,14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def init_clean(x):\n",
    "    temp = x.upper()\n",
    "    temp = temp.strip()\n",
    "    # deleting .0 because not part of official codes\n",
    "    temp = temp.replace(\".0\", \"\")\n",
    "    #sometimes someone writes e.g. H03, but 0 never part of official codes\n",
    "    temp = temp.replace(\"0\",\"\")\n",
    "    #sometimes people use whitespace to separate the letter and the number\n",
    "    temp = temp.replace(\" \",\"\")\n",
    "    return temp\n",
    "\n",
    "def cleaning_codes(x, letter, unique):\n",
    "    if not pd.isna(x):\n",
    "        if x == \"\" or x == \"--\" or x == \"-\":\n",
    "            return np.nan\n",
    "        temp = unidecode.unidecode(x)\n",
    "        # converting cell to list, because sometimes it contains more than one value, replacing other possible separators with commas\n",
    "        temp = temp.replace(\"/\", \",\").replace(\";\",\",\").replace(\"\\n\",\",\").replace(\"，\", \",\")\n",
    "        # basic cleaning\n",
    "        lst = [init_clean(x) for x in temp.split(\",\")]\n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes cell contains only a number. we are assuming they just didn't add the letter (H for example) in this case\n",
    "        lst = [letter + x if letter not in x else x for x in lst]\n",
    "\n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes a cell contains something like this: \"R_\". We are treating this as nan\n",
    "        lst = [x for x in lst if not f\"{letter}_\" in x and not f\"{letter}*\" in x]\n",
    "        if lst != []:\n",
    "            return lst\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: cleaning_codes(x[\"annex_3\"], \"H\", unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_a\"], \"D\", unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_b\"], \"R\", unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some invalid values left. Some are just typos.We convert them to nan because we cannot infer the code that the official wanted to enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['H2',\n 'H4.1H12H13',\n \"H'7\",\n 'H1AH13',\n 'H3H6.1H11',\n 'H8H12',\n 'H4.1H4.2',\n 'H6.',\n 'H31',\n 'H3H12',\n 'H3.1',\n 'H3H4.1H6.1H12H13',\n 'H17',\n 'H1.1',\n 'HP14',\n 'HXX',\n 'HAZ',\n 'HNR',\n 'H33-35',\n 'H3B',\n 'H4.1H12',\n 'H3H6.1',\n 'HE11',\n 'HE13',\n 'H6.2.',\n 'HE12',\n 'HP15',\n 'H811',\n 'H6.1.H11',\n 'H11YH12',\n 'H4',\n 'HE6.1',\n 'H12H13',\n 'HN13',\n 'H1.8',\n 'HN.A.',\n 'H14',\n 'HP3',\n 'H3H4.1',\n 'H9',\n 'HNA',\n 'H8.H12',\n 'H3A',\n 'HNOTSPECIFIED',\n 'HP6',\n 'HA',\n 'H3H6.1H11H12H13',\n 'H4.4',\n 'HO(CAN)',\n 'H6',\n 'H3H4.1H5.1H6.1H8H11H12',\n 'HNEJ',\n 'H3H6.1H11H12',\n 'HN12',\n 'H7',\n 'H6.1(H3)',\n 'HP14EU',\n 'H6.1(3)',\n 'H8.1',\n 'H4.1H5.1H6.1H8H11H12H13',\n 'H4.2H4.3',\n 'H6.1.',\n 'H4.1H6.1',\n 'H4999999999999996',\n 'H4.1H6.1H12',\n 'H34',\n 'HN11',\n 'HEJFARL',\n 'H6.H8',\n 'H112',\n 'H3H6.1H8',\n 'H6.1H',\n 'H3H4.1H12',\n 'H5H13',\n 'HE9',\n 'HETC',\n 'H5',\n 'H12HAZ',\n 'H15',\n 'H4.1.',\n 'HY18',\n 'H41',\n 'H12.1',\n 'HNOTLISTED',\n \"H'6.1\",\n 'H61',\n 'H18',\n 'HE4.3',\n 'H11.12',\n '1-H11',\n 'H5.5',\n 'HE3',\n 'H4.1.H6.1',\n 'H11H12',\n 'H6.1H8',\n 'H6.1H11H12',\n 'H12.',\n 'H8.',\n 'HE4.1',\n 'H3H4.1H12H13',\n 'H3.4',\n 'H',\n 'H8H13',\n 'HN',\n 'H3.',\n 'H6.1-8',\n 'HN4.1']"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I think we can improve cleaning\n",
    "list(set(list(df[df[\"annex_3\"].notna()][\"annex_3\"].explode().unique())) - set(unique_items_a_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['D18',\n 'D',\n 'DCN',\n 'D19',\n 'DBE',\n 'D13+D1',\n 'DJP',\n 'DXX',\n 'DZA',\n 'DIL',\n 'DR3',\n 'DR4',\n 'DLV',\n 'D17',\n 'DAT',\n 'DE',\n 'DUA',\n 'DGB',\n 'HD14',\n 'DR5',\n 'DPR',\n 'DKR']"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(list(df[df[\"annex_4_a\"].notna()][\"annex_4_a\"].explode().unique())) - set(unique_items_a_4_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['RD12', 'R14', 'RXX', 'R16', 'MIXEDR', 'R15', 'R', 'RD1']"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(list(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"].explode().unique())) - set(unique_items_a_4_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(lst,valid):\n",
    "    if isinstance(lst, list):\n",
    "        temp = [x for x in lst if x in valid]\n",
    "        if temp != []:\n",
    "            return temp\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: func(x[\"annex_3\"], unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: func(x[\"annex_4_a\"], unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: func(x[\"annex_4_b\"], unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0                    [H3]\n1          [H6.1, H8, H1]\n2          [H6.1, H8, H1]\n3        [H6.1, H11, H12]\n4        [H6.1, H11, H12]\n               ...       \n94020              [H4.2]\n94021              [H4.2]\n94022           [H1, H11]\n94023                 NaN\n94024                 NaN\nName: annex_3, Length: 94025, dtype: object"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['annex_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_code(h_code):\n",
    "    if type(h_code)!= float:\n",
    "        return [s.replace(\"H\", \"UN\") if s not in (\"H10\", \"H11\", \"H12\", \"H13\") else \"UN9\" for s in h_code]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UN_code'] = df['annex_3'].apply(un_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        if isinstance(x, float):\n",
    "            return x\n",
    "        else:\n",
    "            temp = str(x)\n",
    "            # removing whitespace\n",
    "            temp = temp.replace(\" \", \"\")\n",
    "            # converting , to .\n",
    "            temp = temp.replace(\",\",\".\")\n",
    "            # replacing all non numeric characters but .\n",
    "            temp = re.sub(\"[^0-9.]\", \"\", temp)\n",
    "            temp = float(temp)\n",
    "            return temp\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"amount\"] = df.apply(lambda x: func(x[\"amount\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"year\"] = df.apply(lambda x: func(x[\"year\"]), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop all rows that have missing values for amount and country_of_destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"country\"]==\"NA\"] = np.nan\n",
    "df = df[df['amount'].notna()]\n",
    "df = df[df['country_of_destination'].notna()]\n",
    "df = df[df['country'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost 84 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lost {initial_len - len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " after processing 6630 less rows of annex_3. Initial value: 32224\n"
     ]
    }
   ],
   "source": [
    "missing = df.isna().sum()\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "print(f\" after processing {int(missing_value_df.iloc[[3]].missing) - initial_annex_3} less rows of annex_3. Initial value: {initial_annex_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating separate columns for codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "df[unique_items_un + [\"multiple\", \"unspecified\"]] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if type(row[\"UN_code\"]) != float:\n",
    "        if len(row[\"UN_code\"]) == 1:\n",
    "            df.loc[index, row[\"UN_code\"][0]] = row[\"amount\"]\n",
    "        else:\n",
    "            df.loc[index, \"multiple\"] = row[\"amount\"]\n",
    "    else:\n",
    "        df.loc[index, \"unspecified\"] = row[\"amount\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Renaming colums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "df.rename(columns={\"country\": \"origin\", \"country_of_destination\": \"destination\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "data": {
      "text/plain": "      origin destination    year           annex_3 annex_4_a  annex_4_b  \\\n0         ad          nz  2021.0              [H3]       NaN  [R1, R13]   \n1         ad          pg  2021.0    [H6.1, H8, H1]  [D5, D9]        NaN   \n2         ad          pg  2021.0    [H6.1, H8, H1]  [D5, D9]        NaN   \n3         ad          nz  2021.0  [H6.1, H11, H12]       NaN  [R1, R13]   \n4         ad          nz  2021.0  [H6.1, H11, H12]      [D1]        NaN   \n...      ...         ...     ...               ...       ...        ...   \n94020     gb          de  2001.0            [H4.2]       NaN       [R4]   \n94021     gb          de  2001.0            [H4.2]       NaN       [R4]   \n94022     gb          no  2001.0         [H1, H11]       NaN   [R3, R4]   \n94023     uz          kz  2001.0               NaN       NaN       [R2]   \n94024     uz          tj  2001.0               NaN       NaN       [R5]   \n\n        amount            UN_code  UN1    UN3  ...   UN4.2  UN4.3  UN5.1  \\\n0       500.00              [UN3]  0.0  500.0  ...    0.00    0.0    0.0   \n1       100.00  [UN6.1, UN8, UN1]  0.0    0.0  ...    0.00    0.0    0.0   \n2       100.00  [UN6.1, UN8, UN1]  0.0    0.0  ...    0.00    0.0    0.0   \n3       300.00  [UN6.1, UN9, UN9]  0.0    0.0  ...    0.00    0.0    0.0   \n4       250.00  [UN6.1, UN9, UN9]  0.0    0.0  ...    0.00    0.0    0.0   \n...        ...                ...  ...    ...  ...     ...    ...    ...   \n94020   105.98            [UN4.2]  0.0    0.0  ...  105.98    0.0    0.0   \n94021   105.98            [UN4.2]  0.0    0.0  ...  105.98    0.0    0.0   \n94022     6.00         [UN1, UN9]  0.0    0.0  ...    0.00    0.0    0.0   \n94023  1683.70                NaN  0.0    0.0  ...    0.00    0.0    0.0   \n94024     4.60                NaN  0.0    0.0  ...    0.00    0.0    0.0   \n\n       UN5.2  UN6.1  UN6.2  UN8  UN9  multiple  unspecified  \n0        0.0    0.0    0.0  0.0  0.0       0.0          0.0  \n1        0.0    0.0    0.0  0.0  0.0     100.0          0.0  \n2        0.0    0.0    0.0  0.0  0.0     100.0          0.0  \n3        0.0    0.0    0.0  0.0  0.0     300.0          0.0  \n4        0.0    0.0    0.0  0.0  0.0     250.0          0.0  \n...      ...    ...    ...  ...  ...       ...          ...  \n94020    0.0    0.0    0.0  0.0  0.0       0.0          0.0  \n94021    0.0    0.0    0.0  0.0  0.0       0.0          0.0  \n94022    0.0    0.0    0.0  0.0  0.0       6.0          0.0  \n94023    0.0    0.0    0.0  0.0  0.0       0.0       1683.7  \n94024    0.0    0.0    0.0  0.0  0.0       0.0          4.6  \n\n[93941 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>annex_3</th>\n      <th>annex_4_a</th>\n      <th>annex_4_b</th>\n      <th>amount</th>\n      <th>UN_code</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>...</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>multiple</th>\n      <th>unspecified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H3]</td>\n      <td>NaN</td>\n      <td>[R1, R13]</td>\n      <td>500.00</td>\n      <td>[UN3]</td>\n      <td>0.0</td>\n      <td>500.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>[D5, D9]</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN6.1, UN8, UN1]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>pg</td>\n      <td>2021.0</td>\n      <td>[H6.1, H8, H1]</td>\n      <td>[D5, D9]</td>\n      <td>NaN</td>\n      <td>100.00</td>\n      <td>[UN6.1, UN8, UN1]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>NaN</td>\n      <td>[R1, R13]</td>\n      <td>300.00</td>\n      <td>[UN6.1, UN9, UN9]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>300.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>nz</td>\n      <td>2021.0</td>\n      <td>[H6.1, H11, H12]</td>\n      <td>[D1]</td>\n      <td>NaN</td>\n      <td>250.00</td>\n      <td>[UN6.1, UN9, UN9]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94020</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>[R4]</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>105.98</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>94021</th>\n      <td>gb</td>\n      <td>de</td>\n      <td>2001.0</td>\n      <td>[H4.2]</td>\n      <td>NaN</td>\n      <td>[R4]</td>\n      <td>105.98</td>\n      <td>[UN4.2]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>105.98</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>94022</th>\n      <td>gb</td>\n      <td>no</td>\n      <td>2001.0</td>\n      <td>[H1, H11]</td>\n      <td>NaN</td>\n      <td>[R3, R4]</td>\n      <td>6.00</td>\n      <td>[UN1, UN9]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>94023</th>\n      <td>uz</td>\n      <td>kz</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[R2]</td>\n      <td>1683.70</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1683.7</td>\n    </tr>\n    <tr>\n      <th>94024</th>\n      <td>uz</td>\n      <td>tj</td>\n      <td>2001.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[R5]</td>\n      <td>4.60</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>93941 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregating\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "cols = [\"origin\",\"destination\",\"year\"]\n",
    "agg_functions = {\"UN1\" : \"sum\" ,\"UN3\": \"sum\",\"UN4.1\": \"sum\",\"UN4.2\": \"sum\",\"UN4.3\": \"sum\",\"UN5.1\": \"sum\",\"UN5.2\": \"sum\",\"UN6.1\": \"sum\",\"UN6.2\": \"sum\",\"UN8\": \"sum\",\"UN9\": \"sum\", \"unspecified\": \"sum\", \"multiple\": \"sum\"}\n",
    "df_new = df.groupby(cols, dropna=False).aggregate(agg_functions).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "     origin destination    year  UN1  UN3  UN4.1  UN4.2  UN4.3  UN5.1  UN5.2  \\\n0        ad          es  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n1        ad          es  2003.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n2        ad          es  2004.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n3        ad          es  2005.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n4        ad          es  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n...     ...         ...     ...  ...  ...    ...    ...    ...    ...    ...   \n8121     za          se  2015.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8122     za          sg  2010.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8123     za          tr  2018.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8124     zm          fi  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8125     zm          za  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n\n      UN6.1  UN6.2  UN8     UN9  unspecified  multiple  \n0       0.0    0.0  0.0     0.0     7777.400      0.00  \n1       0.0    0.0  0.0     0.0      486.800      0.00  \n2       0.0    0.0  0.0     0.0      425.980      0.00  \n3       0.0    0.0  0.0     0.0      621.950      0.00  \n4       0.0    0.0  0.0     0.0     1044.092      0.00  \n...     ...    ...  ...     ...          ...       ...  \n8121    0.0    0.0  0.0  1000.0        0.000      0.00  \n8122    0.0    0.0  0.0   720.0        0.000      0.00  \n8123    0.0    0.0  0.0     0.0        0.000     21.24  \n8124    0.0    0.0  0.0     0.0      235.000      0.00  \n8125    0.0    0.0  0.0     0.0        1.700      0.00  \n\n[8126 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7777.400</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2003.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>486.800</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2004.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>425.980</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2005.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>621.950</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1044.092</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8121</th>\n      <td>za</td>\n      <td>se</td>\n      <td>2015.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8122</th>\n      <td>za</td>\n      <td>sg</td>\n      <td>2010.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>720.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8123</th>\n      <td>za</td>\n      <td>tr</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>21.24</td>\n    </tr>\n    <tr>\n      <th>8124</th>\n      <td>zm</td>\n      <td>fi</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8125</th>\n      <td>zm</td>\n      <td>za</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.700</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8126 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[291], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mlen\u001B[39m(df_new[(df_new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munspecified\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m!=\u001B[39m\u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (df_new[[unique_items_un]] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39many(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))])\n",
      "File \u001B[0;32m~/Code/Uni/Basel_Convention_Scraper/venv/lib/python3.10/site-packages/pandas/core/generic.py:1527\u001B[0m, in \u001B[0;36mNDFrame.__nonzero__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1525\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   1526\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__nonzero__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1528\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe truth value of a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is ambiguous. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1529\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1530\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "len(df_new[(df_new[\"unspecified\"]!=0 and (df_new[[unique_items_un]] == 0).any(axis=1))])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584 of 8126 rows have an amount of zero everywhere but unspecified or multiple\n",
      "2368 of 8126 rows have no amount on unspecified and multiple\n",
      "4286 of 8126 rows have an amount on unspecified\n",
      "2099 of 8126 rows have an amount on multiple\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df_new[(df_new.iloc[:,3:14] == 0).all(axis=1)])} of {len(df_new)} rows have an amount of zero everywhere but unspecified or multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:] == 0).all(axis=1)])} of {len(df_new)} rows have no amount on unspecified and multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:15] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on unspecified\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,15:16] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on multiple\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "data": {
      "text/plain": "     origin destination    year  UN1      UN3  UN4.1  UN4.2  UN4.3  UN5.1  \\\n14       ad          es  2016.0  0.0  745.272    0.0    0.0    0.0    0.0   \n15       ad          es  2017.0  0.0  553.091    0.0    0.0    0.0    0.0   \n16       ad          es  2018.0  0.0  311.053    0.0    0.0    0.0    0.0   \n17       ad          es  2019.0  0.0  146.551    0.0    0.0    0.0    0.0   \n18       ad          es  2020.0  0.0  115.578    0.0    0.0    0.0    0.0   \n...     ...         ...     ...  ...      ...    ...    ...    ...    ...   \n8097     za          gb  2020.0  0.0    0.000    0.0    0.0    0.0    0.0   \n8106     za          kp  2018.0  0.0    0.000    0.0    0.0    0.0    0.0   \n8107     za          kr  2007.0  0.0    0.000    0.0    0.0    0.0    0.0   \n8109     za          kr  2014.0  0.0    0.000    0.0    0.0    0.0    0.0   \n8123     za          tr  2018.0  0.0    0.000    0.0    0.0    0.0    0.0   \n\n      UN5.2  UN6.1  UN6.2      UN8        UN9  unspecified   multiple  \n14      0.0    0.0  2.420  193.200   1813.486      205.565     65.992  \n15      0.0    0.0  2.910  178.720   1778.233       24.367     58.424  \n16      0.0    0.0  2.450  169.630   2276.018       33.420     87.723  \n17      0.0    0.0  1.956  193.660   2302.386        9.263     83.732  \n18      0.0    0.0  2.400  224.624   1928.386        5.737     85.755  \n...     ...    ...    ...      ...        ...          ...        ...  \n8097    0.0   10.0  0.000    0.000      0.000        0.000    150.000  \n8106    0.0    0.0  0.000    0.000      0.000        0.000  45000.000  \n8107    0.0    0.0  0.000    0.000      0.000        0.000   5000.000  \n8109    0.0    0.0  0.000    0.000  18200.000     2500.000   5000.000  \n8123    0.0    0.0  0.000    0.000      0.000        0.000     21.240  \n\n[2099 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>745.272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.420</td>\n      <td>193.200</td>\n      <td>1813.486</td>\n      <td>205.565</td>\n      <td>65.992</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2017.0</td>\n      <td>0.0</td>\n      <td>553.091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.910</td>\n      <td>178.720</td>\n      <td>1778.233</td>\n      <td>24.367</td>\n      <td>58.424</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>311.053</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.450</td>\n      <td>169.630</td>\n      <td>2276.018</td>\n      <td>33.420</td>\n      <td>87.723</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2019.0</td>\n      <td>0.0</td>\n      <td>146.551</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.956</td>\n      <td>193.660</td>\n      <td>2302.386</td>\n      <td>9.263</td>\n      <td>83.732</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2020.0</td>\n      <td>0.0</td>\n      <td>115.578</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.400</td>\n      <td>224.624</td>\n      <td>1928.386</td>\n      <td>5.737</td>\n      <td>85.755</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8097</th>\n      <td>za</td>\n      <td>gb</td>\n      <td>2020.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>150.000</td>\n    </tr>\n    <tr>\n      <th>8106</th>\n      <td>za</td>\n      <td>kp</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>45000.000</td>\n    </tr>\n    <tr>\n      <th>8107</th>\n      <td>za</td>\n      <td>kr</td>\n      <td>2007.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>5000.000</td>\n    </tr>\n    <tr>\n      <th>8109</th>\n      <td>za</td>\n      <td>kr</td>\n      <td>2014.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>18200.000</td>\n      <td>2500.000</td>\n      <td>5000.000</td>\n    </tr>\n    <tr>\n      <th>8123</th>\n      <td>za</td>\n      <td>tr</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>21.240</td>\n    </tr>\n  </tbody>\n</table>\n<p>2099 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[(df_new.iloc[:,15:16] != 0).all(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_new.to_csv(\"../output/processed/clean.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Source: https://towardsdatascience.com/dealing-with-list-values-in-pandas-dataframes-a177e534f173\n",
    "# def boolean_df(item_lists, unique_items):# Create empty dict\n",
    "#     bool_dict = {}\n",
    "#\n",
    "#     # Loop through all the tags\n",
    "#     for i, item in enumerate(unique_items):\n",
    "#         # Apply boolean mask\n",
    "#         bool_dict[item] = item_lists.apply(lambda x: item in x)\n",
    "#\n",
    "#     # Return the results as a dataframe\n",
    "#     return pd.DataFrame(bool_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"annex_3\"].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df_bool_h = boolean_df(df[df[\"annex_3\"].notna()][\"annex_3\"], unique_items_a_3)\n",
    "# df_bool_d = boolean_df(df[df['annex_4_a'].notna()][\"annex_4_a\"], unique_items_a_4_a)\n",
    "# df_bool_r = boolean_df(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"], unique_items_a_4_b)\n",
    "# df_bool_un = boolean_df(df[df[\"UN_code\"].notna()][\"UN_code\"], unique_items_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # only using un code for now\n",
    "# df = pd.concat([df[[\"country\", \"country_of_destination\", \"year\", \"amount\"]], df_bool_un], axis=1)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# # df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])] = df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geocoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "# TOKEN=os.getenv(\"MAPBOX_TOKEN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# headers = {'Accept': 'application/json'}\n",
    "# dct = {}\n",
    "# countries = list(df.country.unique())\n",
    "# for i in countries:\n",
    "#     url = f\"https://api.mapbox.com/geocoding/v5/mapbox.places/{i}.json?&types=country&access_token={TOKEN}\"\n",
    "#     r = requests.get(url)\n",
    "#     jason = r.json()\n",
    "#     dct[i] = jason[\"features\"][0][\"center\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     lat = dct[x][0]\n",
    "#     lon = dct[x][1]\n",
    "#     return lat,lon\n",
    "#\n",
    "#\n",
    "# df[\"origin_lat\"],df[\"origin_lon\"] = df.apply(lambda x: func(x[\"country\"]), axis=1)\n",
    "# df[\"destination_lat\"],df[\"destination_lon\"] = df.apply(lambda x: func(x[\"country_of_destination\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "# for i in countries:\n",
    "#     df.loc[df[\"country\"] == i, \"lat_origin\"]=dct[i][1]\n",
    "#     df.loc[df[\"country\"] == i, \"lon_origin\"]=dct[i][0]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lat_destination\"]=dct[i][1]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lon_destination\"]=dct[i][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Renaming columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"../output/processed/clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
