{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import unidecode\n",
    "import pycountry\n",
    "from geojson import FeatureCollection, dump\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25147/3925779474.py:1: DtypeWarning: Columns (0,1,2,3,5,12,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94025 entries, 0 to 94024\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   country                 94025 non-null  object\n",
      " 1   country_of_destination  93982 non-null  object\n",
      " 2   year                    94025 non-null  int64 \n",
      " 3   annex_3                 61801 non-null  object\n",
      " 4   annex_4_a               29088 non-null  object\n",
      " 5   annex_4_b               65992 non-null  object\n",
      " 6   amount                  93990 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/exports.csv\")[[\"country\", \"country_of_destination\", \"year\",\"annex_3\", \"annex_4_a\", \"annex_4_b\", \"amount\"]]\n",
    "df.info()\n",
    "initial_len = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2766720163.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[338], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    initial len\u001B[0m\n\u001B[0m            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "missing = df.isna().sum()\n",
    "initial len\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "initial_annex_3 = int(missing_value_df.iloc[[3]].missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing country names\n",
    "### Converting country name to its alpha 2 code (https://en.wikipedia.org/wiki/ISO_3166-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    # -- Cleaning and formatting country name strings to get recognized by pycountry --\n",
    "    # removing whitespace from beginning and end so country names get recognized properly\n",
    "    temp = x.strip()\n",
    "    # e.g. \"Venezuela (Bolivarian Republic of) -> \"Venezuela, Bolivarian Republic of\"\n",
    "    temp = temp.replace(\" (\",\", \").replace(\")\",\"\")\n",
    "    # Côte d´Ivoire --> Côte d'Ivoire\n",
    "    temp = temp.replace(\"´\", \"'\")\n",
    "    # Handling\n",
    "    if temp == \"United Kingdom of Great Britain and Northern Ireland\":\n",
    "        temp = \"United Kingdom\"\n",
    "    if temp == \"Türkiye\":\n",
    "        temp = \"Turkey\"\n",
    "    if temp == \"Swaziland\":\n",
    "        temp = \"Eswatini\"\n",
    "    if temp == \"Republic of Moldova\":\n",
    "        temp = \"Moldova, Republic of\"\n",
    "    if temp == \"Democratic Republic of the Congo\" or temp == \"Congo, Democratic Republic of the\" or temp == \"Congo, Republic of the\":\n",
    "        temp = \"Congo, The Democratic Republic of the\"\n",
    "    if temp == \"State of Palestine\":\n",
    "        temp = \"Palestine, State of\"\n",
    "    if temp == \"Bolivia\":\n",
    "        temp = \"Bolivia, Plurinational State of\"\n",
    "     # -- Converting country name to alpha_2 code, which is what the other columns use --\n",
    "    return pycountry.countries.get(name=temp).alpha_2.lower()\n",
    "\n",
    "df[\"country\"] = df[\"country\"].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if alpha 2 codes of other columns are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    if not pd.isna(x):\n",
    "        temp = x.strip()\n",
    "        temp = unidecode.unidecode(temp)\n",
    "        temp = temp.replace(\"\\xa0\", \"\")\n",
    "        if temp == \"\":\n",
    "            return np.nan\n",
    "        temp = \"\".join([ c if c.isalnum() else \"\" for c in temp ])\n",
    "        if temp == \"UK\":\n",
    "            temp = \"GB\"\n",
    "        country = pycountry.countries.get(alpha_2=temp)\n",
    "        if country is None:\n",
    "            country = pycountry.countries.get(alpha_3=temp)\n",
    "            if country is None:\n",
    "                # There are still some invalid values left. We treat them as typos and therefore as nan, because we cannot infer the code that the official wanted to enter\n",
    "                print(x)\n",
    "                return np.nan\n",
    "            else:\n",
    "                return country.alpha_2.lower()\n",
    "        else:\n",
    "            return temp.lower()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"country_of_destination\"] = df[\"country_of_destination\"].apply(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning code columns (annex_3, annex_4_a, annex_4_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# NEEDS CONFIRMATION\n",
    "# Valid codes\n",
    "unique_items_a_3 = (\"H1\",\"H3\",\"H4.1\",\"H4.2\",\"H4.3\",\"H5.1\",\"H5.2\",\"H6.1\",\"H6.2\",\"H8\",\"H10\",\"H11\",\"H12\",\"H13\")\n",
    "unique_items_un = [\"UN1\",\"UN3\",\"UN4.1\",\"UN4.2\",\"UN4.3\",\"UN5.1\",\"UN5.2\",\"UN6.1\",\"UN6.2\",\"UN8\",\"UN9\"]\n",
    "unique_items_a_4_a = [f\"D{x}\" for x in range(1,17)]\n",
    "unique_items_a_4_b = [f\"R{x}\" for x in range(1,14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def init_clean(x):\n",
    "    temp = x.upper()\n",
    "    temp = temp.strip()\n",
    "    # deleting .0 because not part of official codes\n",
    "    temp = temp.replace(\".0\", \"\")\n",
    "    #sometimes someone writes e.g. H03, but 0 never part of official codes\n",
    "    temp = temp.replace(\"0\",\"\")\n",
    "    #sometimes people use whitespace to separate the letter and the number\n",
    "    temp = temp.replace(\" \",\"\")\n",
    "    return temp\n",
    "\n",
    "def cleaning_codes(x, letter, unique):\n",
    "    if not pd.isna(x):\n",
    "        if x == \"\" or x == \"--\" or x == \"-\":\n",
    "            return np.nan\n",
    "        temp = unidecode.unidecode(x)\n",
    "        # converting cell to list, because sometimes it contains more than one value, replacing other possible separators with commas\n",
    "        temp = temp.replace(\"/\", \",\").replace(\";\",\",\").replace(\"\\n\",\",\").replace(\"，\", \",\")\n",
    "        # basic cleaning\n",
    "        lst = [init_clean(x) for x in temp.split(\",\")]\n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes cell contains only a number. we are assuming they just didn't add the letter (H for example) in this case\n",
    "        lst = [letter + x if letter not in x else x for x in lst]\n",
    "\n",
    "        # NEEDS CONFIRMATION\n",
    "        # sometimes a cell contains something like this: \"R_\". We are treating this as nan\n",
    "        lst = [x for x in lst if not f\"{letter}_\" in x and not f\"{letter}*\" in x]\n",
    "        if lst != []:\n",
    "            return lst\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: cleaning_codes(x[\"annex_3\"], \"H\", unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_a\"], \"D\", unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: cleaning_codes(x[\"annex_4_b\"], \"R\", unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some invalid values left. Some are just typos.We convert them to nan because we cannot infer the code that the official wanted to enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I think we can improve cleaning\n",
    "list(set(list(df[df[\"annex_3\"].notna()][\"annex_3\"].explode().unique())) - set(unique_items_a_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(set(list(df[df[\"annex_4_a\"].notna()][\"annex_4_a\"].explode().unique())) - set(unique_items_a_4_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(set(list(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"].explode().unique())) - set(unique_items_a_4_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(lst,valid):\n",
    "    if isinstance(lst, list):\n",
    "        temp = [x for x in lst if x in valid]\n",
    "        if temp != []:\n",
    "            return temp\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"annex_3\"] = df.apply(lambda x: func(x[\"annex_3\"], unique_items_a_3), axis=1)\n",
    "df[\"annex_4_a\"] = df.apply(lambda x: func(x[\"annex_4_a\"], unique_items_a_4_a), axis=1)\n",
    "df[\"annex_4_b\"] = df.apply(lambda x: func(x[\"annex_4_b\"], unique_items_a_4_b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annex_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_code(h_code):\n",
    "    if type(h_code)!= float:\n",
    "        return [s.replace(\"H\", \"UN\") if s not in (\"H10\", \"H11\", \"H12\", \"H13\") else \"UN9\" for s in h_code]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UN_code'] = df['annex_3'].apply(un_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        if isinstance(x, float):\n",
    "            return x\n",
    "        else:\n",
    "            temp = str(x)\n",
    "            # removing whitespace\n",
    "            temp = temp.replace(\" \", \"\")\n",
    "            # converting , to .\n",
    "            temp = temp.replace(\",\",\".\")\n",
    "            # replacing all non numeric characters but .\n",
    "            temp = re.sub(\"[^0-9.]\", \"\", temp)\n",
    "            temp = float(temp)\n",
    "            return temp\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"amount\"] = df.apply(lambda x: func(x[\"amount\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if not pd.isna(x):\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"year\"] = df.apply(lambda x: func(x[\"year\"]), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop all rows that have missing values for amount and country_of_destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"country\"]==\"NA\"] = np.nan\n",
    "df = df[df['amount'].notna()]\n",
    "df = df[df['country_of_destination'].notna()]\n",
    "df = df[df['country'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Lost {initial_len - len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "missing = df.isna().sum()\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'missing': missing})\n",
    "\n",
    "print(f\" after processing {int(missing_value_df.iloc[[3]].missing) - initial_annex_3} less rows of annex_3. Initial value: {initial_annex_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating separate columns for codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[unique_items_un + [\"multiple\", \"unspecified\"]] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if type(row[\"UN_code\"]) != float:\n",
    "        if len(row[\"UN_code\"]) == 1:\n",
    "            df.loc[index, row[\"UN_code\"][0]] = row[\"amount\"]\n",
    "        else:\n",
    "            df.loc[index, \"multiple\"] = row[\"amount\"]\n",
    "    else:\n",
    "        df.loc[index, \"unspecified\"] = row[\"amount\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Renaming and deleting colums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.rename(columns={\"country\": \"origin\", \"country_of_destination\": \"destination\"}, inplace=True)\n",
    "df.drop(['amount', 'UN_code', \"annex_3\", \"annex_4_a\", \"annex_4_b\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregating\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = [\"origin\",\"destination\",\"year\"]\n",
    "agg_functions = {\"UN1\" : \"sum\" ,\"UN3\": \"sum\",\"UN4.1\": \"sum\",\"UN4.2\": \"sum\",\"UN4.3\": \"sum\",\"UN5.1\": \"sum\",\"UN5.2\": \"sum\",\"UN6.1\": \"sum\",\"UN6.2\": \"sum\",\"UN8\": \"sum\",\"UN9\": \"sum\", \"unspecified\": \"sum\", \"multiple\": \"sum\"}\n",
    "df_new = df.groupby(cols, dropna=False).aggregate(agg_functions).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_new[(df_new[\"unspecified\"]!=0 and (df_new[[unique_items_un]] == 0).any(axis=1))])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584 of 8126 rows have an amount of zero everywhere but unspecified or multiple\n",
      "850 of 8126 rows have an amount of zero everywhere but unspecified\n",
      "2368 of 8126 rows have no amount on unspecified and multiple\n",
      "4286 of 8126 rows have an amount on unspecified\n",
      "2099 of 8126 rows have an amount on multiple\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df_new[(df_new.iloc[:,3:14] == 0).all(axis=1)])} of {len(df_new)} rows have an amount of zero everywhere but unspecified or multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,3:15] == 0).all(axis=1)])} of {len(df_new)} rows have an amount of zero everywhere but unspecified\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:] == 0).all(axis=1)])} of {len(df_new)} rows have no amount on unspecified and multiple\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,14:15] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on unspecified\")\n",
    "print(f\"{len(df_new[(df_new.iloc[:,15:16] != 0).all(axis=1)])} of {len(df_new)} rows have an amount on multiple\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "data": {
      "text/plain": "     origin destination    year  UN1  UN3  UN4.1  UN4.2  UN4.3  UN5.1  UN5.2  \\\n0        ad          es  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n1        ad          es  2003.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n2        ad          es  2004.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n3        ad          es  2005.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n4        ad          es  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n...     ...         ...     ...  ...  ...    ...    ...    ...    ...    ...   \n8121     za          se  2015.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8122     za          sg  2010.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8123     za          tr  2018.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8124     zm          fi  2002.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n8125     zm          za  2006.0  0.0  0.0    0.0    0.0    0.0    0.0    0.0   \n\n      UN6.1  UN6.2  UN8     UN9  unspecified  multiple  \n0       0.0    0.0  0.0     0.0     7777.400      0.00  \n1       0.0    0.0  0.0     0.0      486.800      0.00  \n2       0.0    0.0  0.0     0.0      425.980      0.00  \n3       0.0    0.0  0.0     0.0      621.950      0.00  \n4       0.0    0.0  0.0     0.0     1044.092      0.00  \n...     ...    ...  ...     ...          ...       ...  \n8121    0.0    0.0  0.0  1000.0        0.000      0.00  \n8122    0.0    0.0  0.0   720.0        0.000      0.00  \n8123    0.0    0.0  0.0     0.0        0.000     21.24  \n8124    0.0    0.0  0.0     0.0      235.000      0.00  \n8125    0.0    0.0  0.0     0.0        1.700      0.00  \n\n[8126 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>year</th>\n      <th>UN1</th>\n      <th>UN3</th>\n      <th>UN4.1</th>\n      <th>UN4.2</th>\n      <th>UN4.3</th>\n      <th>UN5.1</th>\n      <th>UN5.2</th>\n      <th>UN6.1</th>\n      <th>UN6.2</th>\n      <th>UN8</th>\n      <th>UN9</th>\n      <th>unspecified</th>\n      <th>multiple</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7777.400</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2003.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>486.800</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2004.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>425.980</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2005.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>621.950</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ad</td>\n      <td>es</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1044.092</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8121</th>\n      <td>za</td>\n      <td>se</td>\n      <td>2015.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8122</th>\n      <td>za</td>\n      <td>sg</td>\n      <td>2010.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>720.0</td>\n      <td>0.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8123</th>\n      <td>za</td>\n      <td>tr</td>\n      <td>2018.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>21.24</td>\n    </tr>\n    <tr>\n      <th>8124</th>\n      <td>zm</td>\n      <td>fi</td>\n      <td>2002.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.000</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8125</th>\n      <td>zm</td>\n      <td>za</td>\n      <td>2006.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.700</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8126 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "df_new.to_csv(\"../output/processed/clean.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Source: https://towardsdatascience.com/dealing-with-list-values-in-pandas-dataframes-a177e534f173\n",
    "# def boolean_df(item_lists, unique_items):# Create empty dict\n",
    "#     bool_dict = {}\n",
    "#\n",
    "#     # Loop through all the tags\n",
    "#     for i, item in enumerate(unique_items):\n",
    "#         # Apply boolean mask\n",
    "#         bool_dict[item] = item_lists.apply(lambda x: item in x)\n",
    "#\n",
    "#     # Return the results as a dataframe\n",
    "#     return pd.DataFrame(bool_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"annex_3\"].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df_bool_h = boolean_df(df[df[\"annex_3\"].notna()][\"annex_3\"], unique_items_a_3)\n",
    "# df_bool_d = boolean_df(df[df['annex_4_a'].notna()][\"annex_4_a\"], unique_items_a_4_a)\n",
    "# df_bool_r = boolean_df(df[df[\"annex_4_b\"].notna()][\"annex_4_b\"], unique_items_a_4_b)\n",
    "# df_bool_un = boolean_df(df[df[\"UN_code\"].notna()][\"UN_code\"], unique_items_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bool_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # only using un code for now\n",
    "# df = pd.concat([df[[\"country\", \"country_of_destination\", \"year\", \"amount\"]], df_bool_un], axis=1)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# # df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])] = df[df.columns.intersection([*unique_items_a_3, *unique_items_a_4_a, *unique_items_a_4_b])].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geocoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "# TOKEN=os.getenv(\"MAPBOX_TOKEN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# headers = {'Accept': 'application/json'}\n",
    "# dct = {}\n",
    "# countries = list(df.country.unique())\n",
    "# for i in countries:\n",
    "#     url = f\"https://api.mapbox.com/geocoding/v5/mapbox.places/{i}.json?&types=country&access_token={TOKEN}\"\n",
    "#     r = requests.get(url)\n",
    "#     jason = r.json()\n",
    "#     dct[i] = jason[\"features\"][0][\"center\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     lat = dct[x][0]\n",
    "#     lon = dct[x][1]\n",
    "#     return lat,lon\n",
    "#\n",
    "#\n",
    "# df[\"origin_lat\"],df[\"origin_lon\"] = df.apply(lambda x: func(x[\"country\"]), axis=1)\n",
    "# df[\"destination_lat\"],df[\"destination_lon\"] = df.apply(lambda x: func(x[\"country_of_destination\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in countries:\n",
    "#     df.loc[df[\"country\"] == i, \"lat_origin\"]=dct[i][1]\n",
    "#     df.loc[df[\"country\"] == i, \"lon_origin\"]=dct[i][0]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lat_destination\"]=dct[i][1]\n",
    "#     df.loc[df[\"country_of_destination\"] == i, \"lon_destination\"]=dct[i][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Renaming columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"../output/processed/clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
